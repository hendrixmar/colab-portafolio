{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"tarea.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyP+p/aeZJ2hFMb5aSxhn8/A"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"17a8gdd2E8gw","colab_type":"code","colab":{}},"source":["from keras.datasets import mnist\n","import matplotlib.pyplot as plt\n","import numpy as np\n","\n","(X_train, y_train), (X_test, y_test) = mnist.load_data()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"JKTlIfojXk1w","colab_type":"code","colab":{}},"source":["from keras.utils import to_categorical#one-hot encode target column\n","\n","X_train = X_train.reshape(60000,28,28,1)\n","X_test = X_test.reshape(10000,28,28,1)\n","\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"H23386BHaS43","colab_type":"text"},"source":["Utilice la funcion to_categorical para generar un *one hot encode* para las etiquetas del dataset de entrenamiento y de pruebas"]},{"cell_type":"code","metadata":{"id":"82zKK_x6aSTk","colab_type":"code","colab":{}},"source":["y_train = to_categorical(y_train)\n","y_test = to_categorical(y_test)\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wFJQjDETaMcR","colab_type":"text"},"source":["La arquitectura de esta red neuronal es muy sencilla. Consta de dos capas convolusionales. La primera capa Consta de 64 nodos y la siguiente consta de 32 nodos. Como funcion de activacion utilice el relu que sido demostrado trabajar muy bien con las redes neuronales. Ademas de que mejora los tiempos de entrenamientos debido a que su parcial mapea a 0 o 1. La capa de flatten tiene la funcion de conectar la capa densamente conectada con la capa convolucional."]},{"cell_type":"code","metadata":{"id":"WI6i1KDnX4Bb","colab_type":"code","colab":{}},"source":["from keras.models import Sequential\n","from keras.layers import Dense, Conv2D, Flatten\n","#create model\n","\n","model = Sequential()\n","model.add(Conv2D(64, kernel_size=3, activation='relu', input_shape=(28,28,1)))\n","model.add(Conv2D(32, kernel_size=3, activation='relu'))\n","model.add(Flatten())\n","model.add(Dense(10, activation='softmax'))\n","\n","model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5hvz0k3Fhi9e","colab_type":"text"},"source":[""]},{"cell_type":"code","metadata":{"id":"oS1MtSPhX_Bf","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":164},"outputId":"2bcfe7fb-bb13-4094-d804-959b69099a80","executionInfo":{"status":"ok","timestamp":1592000471262,"user_tz":300,"elapsed":541332,"user":{"displayName":"hendrik Martina","photoUrl":"","userId":"05716117210214543831"}}},"source":["#Entrenar el modelo\n","model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=3)"],"execution_count":18,"outputs":[{"output_type":"stream","text":["Train on 60000 samples, validate on 10000 samples\n","Epoch 1/3\n","60000/60000 [==============================] - 182s 3ms/step - loss: 0.2322 - accuracy: 0.9516 - val_loss: 0.0878 - val_accuracy: 0.9748\n","Epoch 2/3\n","60000/60000 [==============================] - 179s 3ms/step - loss: 0.0676 - accuracy: 0.9792 - val_loss: 0.0765 - val_accuracy: 0.9780\n","Epoch 3/3\n","60000/60000 [==============================] - 179s 3ms/step - loss: 0.0503 - accuracy: 0.9846 - val_loss: 0.0829 - val_accuracy: 0.9759\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.callbacks.History at 0x7f39cb618f28>"]},"metadata":{"tags":[]},"execution_count":18}]},{"cell_type":"code","metadata":{"id":"0lenTg-Ukvdz","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":54},"outputId":"51d9b254-aacd-4a04-d02a-8f9a43c64436","executionInfo":{"status":"ok","timestamp":1592000483834,"user_tz":300,"elapsed":553900,"user":{"displayName":"hendrik Martina","photoUrl":"","userId":"05716117210214543831"}}},"source":["test_loss, test_acc = model.evaluate(X_test,  y_test, verbose=2)\n","y_pred = []\n","\n","for i in model.predict(X_test):\n","    y_pred.append(np.argmax(i))\n","\n","y_pred = np.array(y_pred)\n","print('\\nPrueba de precision:', test_acc)"],"execution_count":19,"outputs":[{"output_type":"stream","text":["\n","Prueba de precision: 0.9758999943733215\n"],"name":"stdout"}]}]}