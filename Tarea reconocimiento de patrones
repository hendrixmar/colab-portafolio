{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Tarea reconocimiento de patrones","provenance":[],"collapsed_sections":[],"toc_visible":true,"mount_file_id":"1Yeor04Wqo6364O9AiKFDU4MN14JhnWQ2","authorship_tag":"ABX9TyMXLvsXGxIF8HLEOENLZ6ny"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"zFswTV1B5gvs","colab_type":"text"},"source":["My dataset is composed by the letter h hand written in a \n","<img src=\"https://i.imgur.com/yQZKUcZ.jpg\">"]},{"cell_type":"code","metadata":{"id":"jv_7F7mF7mSC","colab_type":"code","colab":{}},"source":["import matplotlib.pyplot as plt\n","from mpl_toolkits.axes_grid1 import ImageGrid\n","import numpy as np\n","import imageio\n","import os\n","\n","training = []\n","binarized_training = []\n","test = []\n","binarized_test = []\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"L1D1Us0rd67c","colab_type":"text"},"source":[""]},{"cell_type":"markdown","metadata":{"id":"pyKVI-QcCifX","colab_type":"text"},"source":["#**Loading the images and flatting**\n","The following task to do is to load all the images from our dataset that are composed by 20 images of the letter H hand written. Each image have a size in pixel of 100x100, so it will be represented a as vector of 10000 dimensions.\n","\n"]},{"cell_type":"code","metadata":{"id":"Sd4DD3Bh9lP5","colab_type":"code","colab":{}},"source":["graph = []\n","\n","for img_file in os.listdir(\"images\"):\n","\n","    if img_file == \"Z.jpg\":\n","        different_letter = imageio.imread(f\"images/{img_file}\",as_gray=True).flatten()\n","        continue\n","\n","    img = imageio.imread(f\"images/{img_file}\",as_gray=True).flatten()\n","    \n","    if len(training) < 15:\n","        training.append(img)\n","        binarized_training.append(img < 120)\n","        \n","    else:\n","        test.append(img)\n","        binarized_test.append(img < 120)\n","\n","training = np.array(training)\n","binarized_training = np.array(binarized_training)\n","test = np.array(test)\n","binarized_test = np.array(binarized_test)\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"M2IOpEsbLlXT","colab_type":"text"},"source":["#**Creating the Mean vector**\n","For the binarized I use the threshold of 0.5 to state if it is a 0 or a 1.\n","\n"]},{"cell_type":"code","metadata":{"id":"DFZxGLzE-4QF","colab_type":"code","colab":{}},"source":["\n","mean_vector = []\n","mean_vector_b = []\n","\n","for i in range(10000):\n","    temp = np.mean(training[:,i])\n","    mean_vector.append(temp)\n","\n","for i in range(10000):\n","    temp = np.mean(binarized_training[:,i]) < 0.5\n","    mean_vector_b.append(temp)\n","\n","mean_vector_b = np.array(mean_vector_b)\n","mean_vector = np.array(mean_vector)\n","#plt.hist(mean_vector)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nhbXop3paBaU","colab_type":"text"},"source":["#**Result with the vectors not binarized**\n","In this section we are applying eclidean distance for each image in the test set. It seems that the test set have a lower distance between the mean vector compared with the letter different letter of the set (in this case is the letter \"O\"). But this is the not binarized version. \n"]},{"cell_type":"code","metadata":{"id":"B9dXm2R9NTxb","colab_type":"code","outputId":"26f5ab9b-3c87-49d4-e769-981aeb2bb023","executionInfo":{"status":"ok","timestamp":1589475009750,"user_tz":300,"elapsed":1084,"user":{"displayName":"hendrik Martina","photoUrl":"","userId":"05716117210214543831"}},"colab":{"base_uri":"https://localhost:8080/","height":52}},"source":["eclidean = []\n","for images in test:\n","    \n","    temp = np.linalg.norm(mean_vector-images)\n","    eclidean.append(temp)\n","\n","print(eclidean)\n","print(np.linalg.norm(mean_vector-different_letter))"],"execution_count":4,"outputs":[{"output_type":"stream","text":["[1260.8328, 4064.8198, 2598.9866, 4011.2979, 2096.891]\n","11894.291\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"EkfMcqM2PjIj","colab_type":"text"},"source":["\n","#**Result with the vectors binarized**\n","Now I proceed to make the test with images binarized. The result is worst than the not binarized version and I think is due to the fact we have to define a threshold to map to 0 or 1. Because the original image is grayscale image and the values range from 0 to 255. \n","\n"]},{"cell_type":"code","metadata":{"id":"lqp1WnPfPkt0","colab_type":"code","outputId":"d28247c6-b02a-4987-9c89-7a3789fed945","executionInfo":{"status":"ok","timestamp":1589475009752,"user_tz":300,"elapsed":1082,"user":{"displayName":"hendrik Martina","photoUrl":"","userId":"05716117210214543831"}},"colab":{"base_uri":"https://localhost:8080/","height":52}},"source":["eclidean_b = []\n","for images in binarized_test:\n","    \n","    temp = np.linalg.norm(mean_vector_b^images)\n","    eclidean_b.append(temp)\n","\n","print(eclidean_b)\n","print(np.linalg.norm(mean_vector_b ^(different_letter < 120)))"],"execution_count":5,"outputs":[{"output_type":"stream","text":["[93.00537618869137, 59.724366886556446, 86.92525524840292, 80.20598481410225, 92.1737489744233]\n","75.35914012248281\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"KQCRsfGKVcp-","colab_type":"text"},"source":["# **What would be the difference if the images were not binarized?**\n","There is a problem in both cases. If it is binarized, the accuracy of the model will strictly depend in the threshold to binarize the grayscale image. And finally to produce the mean of the different dimension of the vector it also requieres a threshold. Becuase the mean will be a value that range from 0 to 1. So to discretize that value we requiere a second threshold."]},{"cell_type":"markdown","metadata":{"id":"AztbUnd4cQHe","colab_type":"text"},"source":["#**Suppose you must recognize a sequence of letters and do not have the images cuts corresponding to each letter, how would it proceed? What process would be needed? At what stage should i go?**\n","\n","It will be a good aproach to use a image of the letter we are trying to recognize as a convolutional filter aplying it exhaustively to the whole image. And take the cordinate of the segment that match the most of the filter image. "]}]}