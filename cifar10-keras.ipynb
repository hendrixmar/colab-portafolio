{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"name":"cifar10-keras.ipynb","provenance":[]},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"_uuid":"d613653b3dbe13f8fc31d911de09ad505dd1276e","id":"Fr1Mn0gNq39R","colab_type":"text"},"source":["# Solving CIFAR 10 using Keras (Work in progress)"]},{"cell_type":"markdown","metadata":{"_uuid":"463394145fc7b5c95e013feabf9c67444f7d69f6","id":"Co5-xZeqq39U","colab_type":"text"},"source":["The CIFAR-10 dataset consists of 60000 32x32 colour images in 10 classes, with 6000 images per class. There are 50000 training images and 10000 test images. \n","\n","This notebook attempts to classify those images."]},{"cell_type":"code","metadata":{"trusted":true,"_uuid":"d2890b47f1d662117ddc29e10dd0738792ddb0a3","id":"gz3ilWgNq39W","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593293368059,"user_tz":300,"elapsed":1067,"user":{"displayName":"hendrik Martina","photoUrl":"","userId":"05716117210214543831"}}},"source":["# Import all modules\n","import time\n","import matplotlib.pyplot as plt\n","import numpy as np\n","from keras.models import Sequential\n","from keras.layers import Dense\n","from keras.layers import Dropout\n","from keras.layers import Flatten\n","from keras.constraints import maxnorm\n","from keras.optimizers import SGD\n","from keras.layers import Activation\n","from keras.layers.convolutional import Conv2D\n","from keras.layers.convolutional import MaxPooling2D\n","from keras.layers.normalization import BatchNormalization\n","from keras.utils import np_utils\n","#from keras_sequential_ascii import sequential_model_to_ascii_printout\n","from keras import backend as K\n","\n","\n","# Import Tensorflow with multiprocessing\n","import tensorflow as tf\n","import multiprocessing as mp\n"," \n","# Loading the CIFAR-10 datasets\n","from keras.datasets import cifar10"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"_uuid":"ab7b5a1e21f7d0d79abf7cf401170111d3894076","id":"qvZTlxvMq39g","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593293368646,"user_tz":300,"elapsed":1649,"user":{"displayName":"hendrik Martina","photoUrl":"","userId":"05716117210214543831"}}},"source":["#Declaring Variables\n","batch_size = 32 #Smaller Batch size means more updates in one epoch\n","\n","num_classes = 10 \n","epochs = 100 #Repeat 100 times"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"_uuid":"5119cbf2f1a55a4e62f8c1f1d69219d27a12b158","id":"MWM2z41fq39m","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593293368648,"user_tz":300,"elapsed":1646,"user":{"displayName":"hendrik Martina","photoUrl":"","userId":"05716117210214543831"}}},"source":["#Load the Dataset \n","(x_train, y_train), (x_test,y_test) = cifar10.load_data()"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"_uuid":"89d5e28e037a4fb36da0d47e2554ec97d5ccb1a5","id":"o35yr5S8q39s","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":457},"executionInfo":{"status":"error","timestamp":1593293368935,"user_tz":300,"elapsed":1926,"user":{"displayName":"hendrik Martina","photoUrl":"","userId":"05716117210214543831"}},"outputId":"5bb5c338-5651-4e1e-bef9-7b3aa8884752"},"source":["# Print 10 random images \n","fig = plt.figure(figsize=(8,3))\n","for i in range(num_classes):\n","    ax = fig.add_subplot(2,5,1 + i, xticks=[],yticks=[])\n","    idx = np.where(y_train[:]==i)[0]\n","    features_idx = x_train[idx,::]\n","    img_num = np.random.randint(features_idx.shape[0])\n","    im = np.transpose(features_idx[img_num,::],(1,2,0))\n","    #ax.set_title(class_names[i])\n","    plt.imshow(im)\n","plt.show()"],"execution_count":8,"outputs":[{"output_type":"error","ename":"TypeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-8-e254240a2545>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures_idx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mimg_num\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m#ax.set_title(class_names[i])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mimshow\u001b[0;34m(X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, shape, filternorm, filterrad, imlim, resample, url, data, **kwargs)\u001b[0m\n\u001b[1;32m   2649\u001b[0m         \u001b[0mfilternorm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilternorm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilterrad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilterrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimlim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimlim\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2650\u001b[0m         resample=resample, url=url, **({\"data\": data} if data is not\n\u001b[0;32m-> 2651\u001b[0;31m         None else {}), **kwargs)\n\u001b[0m\u001b[1;32m   2652\u001b[0m     \u001b[0msci\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__ret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2653\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m__ret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1563\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1565\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msanitize_sequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1566\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1567\u001b[0m         \u001b[0mbound\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_sig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/cbook/deprecation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    356\u001b[0m                 \u001b[0;34mf\"%(removal)s.  If any parameter follows {name!r}, they \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m                 f\"should be pass as keyword, not positionally.\")\n\u001b[0;32m--> 358\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/cbook/deprecation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    356\u001b[0m                 \u001b[0;34mf\"%(removal)s.  If any parameter follows {name!r}, they \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m                 f\"should be pass as keyword, not positionally.\")\n\u001b[0;32m--> 358\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mimshow\u001b[0;34m(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, shape, filternorm, filterrad, imlim, resample, url, **kwargs)\u001b[0m\n\u001b[1;32m   5624\u001b[0m                               resample=resample, **kwargs)\n\u001b[1;32m   5625\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5626\u001b[0;31m         \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5627\u001b[0m         \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_alpha\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5628\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_clip_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/image.py\u001b[0m in \u001b[0;36mset_data\u001b[0;34m(self, A)\u001b[0m\n\u001b[1;32m    697\u001b[0m                 or self._A.ndim == 3 and self._A.shape[-1] in [3, 4]):\n\u001b[1;32m    698\u001b[0m             raise TypeError(\"Invalid shape {} for image data\"\n\u001b[0;32m--> 699\u001b[0;31m                             .format(self._A.shape))\n\u001b[0m\u001b[1;32m    700\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_A\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: Invalid shape (32, 3, 32) for image data"]},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAFwAAABcCAYAAADj79JYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAABKUlEQVR4nO3dsVHEMBBAUYuhhCNG/ddiF0EMPYjsIhx4gM/M8V66CnZ+oHTHWmuj8/TXC/w3gscEjwkeEzwmeOz5yuPb7bbmnL+0yuM4juNjrfXy1exS8Dnntu/7z2z1wMYYb2czX0pM8JjgMcFjgscEjwkeEzwmeEzwmOAxwWOCxwSPCR4TPCZ4TPCY4DHBY4LHBI8JHhM8JnhM8JjgMcFjgscEjwkeEzwmeEzwmOAxwWOCxwSPCR4TPCZ4TPCY4DHBY4LHBI8JHhM8JnhM8JjgMcFjgscEjwkeEzwmeEzwmOAxwWOCxwSPCR4TPCZ4TPCY4DHBY4LHBI8JHhM8Nq4cMB1jvG/bdnoUiLvXs0tVl4Lzfb6UmOAxwWOCxwSPCR4TPCZ4TPDYJ+iLGlmbjO3HAAAAAElFTkSuQmCC\n","text/plain":["<Figure size 576x216 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"_uuid":"efbbdc99b70b780994b2976898c7be25ca9456ad","id":"8rs4JQGbq39y","colab_type":"text"},"source":["We now need to normalize the pixel values. This means to turn them from in the range of 0-255 to be between 0 and 1. "]},{"cell_type":"code","metadata":{"trusted":true,"_uuid":"5d46fe18119002f701ef2e01c70cca6a66f54f44","id":"0Xta-m1Bq390","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593293376145,"user_tz":300,"elapsed":824,"user":{"displayName":"hendrik Martina","photoUrl":"","userId":"05716117210214543831"}}},"source":["y_train = np_utils.to_categorical(y_train, num_classes)\n","y_test = np_utils.to_categorical(y_test, num_classes)\n","x_train = x_train.astype('float32')\n","x_test = x_test.astype('float32')\n","x_train  /= 255\n","x_test /= 255"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"_uuid":"865b5067783aa7d3c75349fd025278527563f134","id":"AkTCqxB3q396","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1593295161977,"user_tz":300,"elapsed":1786650,"user":{"displayName":"hendrik Martina","photoUrl":"","userId":"05716117210214543831"}},"outputId":"b6d8cefa-5c88-482b-8c13-f35173cb9605"},"source":["#Defining our model \n","def base_model():\n","    model = Sequential()\n","    model.add(Conv2D(32,(3,3), padding='same', input_shape=x_train.shape[1:]))\n","    model.add(Activation('relu'))\n","    model.add(Conv2D(32,(3,3)))\n","    model.add(Activation('relu'))\n","    model.add(MaxPooling2D(pool_size=(2,2)))\n","    model.add(Dropout(0.25))\n","    \n","    model.add(Conv2D(64, (3, 3), padding='same'))\n","    model.add(Activation('relu'))\n","    model.add(Conv2D(64, (3,3)))\n","    model.add(Activation('relu'))\n","    model.add(MaxPooling2D(pool_size=(2,2)))\n","    model.add(Dropout(0.25))\n","    \n","    model.add(Flatten())\n","    model.add(Dense(521))\n","    model.add(Activation('relu'))\n","    model.add(Dropout(0.5))\n","    model.add(Dense(num_classes))\n","    model.add(Activation('softmax'))\n","    \n","    sgd = SGD(lr = 0.1, decay=1e-6, momentum=0.9, nesterov=True)\n","    \n","    #Train model\n","    model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n","    return model\n","\n","cnn_n = base_model()\n","cnn_n.summary()\n"," \n","#Fit model\n"," \n","cnn = cnn_n.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_data=(x_test,y_test),shuffle=True)     \n","    "],"execution_count":10,"outputs":[{"output_type":"stream","text":["Model: \"sequential_1\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d_1 (Conv2D)            (None, 32, 32, 32)        896       \n","_________________________________________________________________\n","activation_1 (Activation)    (None, 32, 32, 32)        0         \n","_________________________________________________________________\n","conv2d_2 (Conv2D)            (None, 30, 30, 32)        9248      \n","_________________________________________________________________\n","activation_2 (Activation)    (None, 30, 30, 32)        0         \n","_________________________________________________________________\n","max_pooling2d_1 (MaxPooling2 (None, 15, 15, 32)        0         \n","_________________________________________________________________\n","dropout_1 (Dropout)          (None, 15, 15, 32)        0         \n","_________________________________________________________________\n","conv2d_3 (Conv2D)            (None, 15, 15, 64)        18496     \n","_________________________________________________________________\n","activation_3 (Activation)    (None, 15, 15, 64)        0         \n","_________________________________________________________________\n","conv2d_4 (Conv2D)            (None, 13, 13, 64)        36928     \n","_________________________________________________________________\n","activation_4 (Activation)    (None, 13, 13, 64)        0         \n","_________________________________________________________________\n","max_pooling2d_2 (MaxPooling2 (None, 6, 6, 64)          0         \n","_________________________________________________________________\n","dropout_2 (Dropout)          (None, 6, 6, 64)          0         \n","_________________________________________________________________\n","flatten_1 (Flatten)          (None, 2304)              0         \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 521)               1200905   \n","_________________________________________________________________\n","activation_5 (Activation)    (None, 521)               0         \n","_________________________________________________________________\n","dropout_3 (Dropout)          (None, 521)               0         \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 10)                5220      \n","_________________________________________________________________\n","activation_6 (Activation)    (None, 10)                0         \n","=================================================================\n","Total params: 1,271,693\n","Trainable params: 1,271,693\n","Non-trainable params: 0\n","_________________________________________________________________\n","Train on 50000 samples, validate on 10000 samples\n","Epoch 1/100\n","50000/50000 [==============================] - 24s 483us/step - loss: 2.3098 - accuracy: 0.1006 - val_loss: 2.3094 - val_accuracy: 0.1000\n","Epoch 2/100\n","50000/50000 [==============================] - 17s 350us/step - loss: 2.3090 - accuracy: 0.0997 - val_loss: 2.3044 - val_accuracy: 0.1000\n","Epoch 3/100\n","50000/50000 [==============================] - 17s 349us/step - loss: 2.3093 - accuracy: 0.0985 - val_loss: 2.3096 - val_accuracy: 0.1000\n","Epoch 4/100\n","50000/50000 [==============================] - 18s 367us/step - loss: 2.3092 - accuracy: 0.0995 - val_loss: 2.3071 - val_accuracy: 0.1000\n","Epoch 5/100\n","50000/50000 [==============================] - 18s 351us/step - loss: 2.3088 - accuracy: 0.0995 - val_loss: 2.3060 - val_accuracy: 0.1000\n","Epoch 6/100\n","50000/50000 [==============================] - 17s 350us/step - loss: 2.3092 - accuracy: 0.0975 - val_loss: 2.3064 - val_accuracy: 0.1000\n","Epoch 7/100\n","50000/50000 [==============================] - 18s 352us/step - loss: 2.3089 - accuracy: 0.0985 - val_loss: 2.3090 - val_accuracy: 0.1000\n","Epoch 8/100\n","50000/50000 [==============================] - 18s 353us/step - loss: 2.3093 - accuracy: 0.1005 - val_loss: 2.3075 - val_accuracy: 0.1000\n","Epoch 9/100\n","50000/50000 [==============================] - 18s 353us/step - loss: 2.3093 - accuracy: 0.0984 - val_loss: 2.3073 - val_accuracy: 0.1000\n","Epoch 10/100\n","50000/50000 [==============================] - 18s 351us/step - loss: 2.3095 - accuracy: 0.0992 - val_loss: 2.3067 - val_accuracy: 0.1000\n","Epoch 11/100\n","50000/50000 [==============================] - 18s 363us/step - loss: 2.3093 - accuracy: 0.1001 - val_loss: 2.3120 - val_accuracy: 0.1000\n","Epoch 12/100\n","50000/50000 [==============================] - 18s 353us/step - loss: 2.3091 - accuracy: 0.1006 - val_loss: 2.3098 - val_accuracy: 0.1000\n","Epoch 13/100\n","50000/50000 [==============================] - 17s 347us/step - loss: 2.3093 - accuracy: 0.0997 - val_loss: 2.3053 - val_accuracy: 0.1000\n","Epoch 14/100\n","50000/50000 [==============================] - 18s 350us/step - loss: 2.3090 - accuracy: 0.1012 - val_loss: 2.3035 - val_accuracy: 0.1000\n","Epoch 15/100\n","50000/50000 [==============================] - 18s 351us/step - loss: 2.3092 - accuracy: 0.1019 - val_loss: 2.3090 - val_accuracy: 0.1000\n","Epoch 16/100\n","50000/50000 [==============================] - 18s 350us/step - loss: 2.3095 - accuracy: 0.0979 - val_loss: 2.3075 - val_accuracy: 0.1000\n","Epoch 17/100\n","50000/50000 [==============================] - 18s 352us/step - loss: 2.3094 - accuracy: 0.0991 - val_loss: 2.3091 - val_accuracy: 0.1000\n","Epoch 18/100\n","50000/50000 [==============================] - 18s 353us/step - loss: 2.3084 - accuracy: 0.1012 - val_loss: 2.3069 - val_accuracy: 0.1000\n","Epoch 19/100\n","50000/50000 [==============================] - 18s 357us/step - loss: 2.3093 - accuracy: 0.0997 - val_loss: 2.3068 - val_accuracy: 0.1000\n","Epoch 20/100\n","50000/50000 [==============================] - 18s 356us/step - loss: 2.3090 - accuracy: 0.1013 - val_loss: 2.3093 - val_accuracy: 0.1000\n","Epoch 21/100\n","50000/50000 [==============================] - 18s 364us/step - loss: 2.3089 - accuracy: 0.0994 - val_loss: 2.3056 - val_accuracy: 0.1000\n","Epoch 22/100\n","50000/50000 [==============================] - 18s 358us/step - loss: 2.3090 - accuracy: 0.1011 - val_loss: 2.3044 - val_accuracy: 0.1000\n","Epoch 23/100\n","50000/50000 [==============================] - 18s 351us/step - loss: 2.3088 - accuracy: 0.0998 - val_loss: 2.3039 - val_accuracy: 0.1000\n","Epoch 24/100\n","50000/50000 [==============================] - 18s 351us/step - loss: 2.3092 - accuracy: 0.0976 - val_loss: 2.3080 - val_accuracy: 0.1000\n","Epoch 25/100\n","50000/50000 [==============================] - 18s 352us/step - loss: 2.3090 - accuracy: 0.0990 - val_loss: 2.3078 - val_accuracy: 0.1000\n","Epoch 26/100\n","50000/50000 [==============================] - 17s 348us/step - loss: 2.3092 - accuracy: 0.0962 - val_loss: 2.3102 - val_accuracy: 0.1000\n","Epoch 27/100\n","50000/50000 [==============================] - 17s 349us/step - loss: 2.3084 - accuracy: 0.1002 - val_loss: 2.3107 - val_accuracy: 0.1000\n","Epoch 28/100\n","50000/50000 [==============================] - 18s 361us/step - loss: 2.3084 - accuracy: 0.1004 - val_loss: 2.3074 - val_accuracy: 0.1000\n","Epoch 29/100\n","50000/50000 [==============================] - 18s 354us/step - loss: 2.3091 - accuracy: 0.0998 - val_loss: 2.3168 - val_accuracy: 0.1000\n","Epoch 30/100\n","50000/50000 [==============================] - 18s 352us/step - loss: 2.3087 - accuracy: 0.1009 - val_loss: 2.3070 - val_accuracy: 0.1000\n","Epoch 31/100\n","50000/50000 [==============================] - 18s 353us/step - loss: 2.3086 - accuracy: 0.1019 - val_loss: 2.3073 - val_accuracy: 0.1000\n","Epoch 32/100\n","50000/50000 [==============================] - 18s 354us/step - loss: 2.3090 - accuracy: 0.1000 - val_loss: 2.3122 - val_accuracy: 0.1000\n","Epoch 33/100\n","50000/50000 [==============================] - 18s 352us/step - loss: 2.3092 - accuracy: 0.0972 - val_loss: 2.3110 - val_accuracy: 0.1000\n","Epoch 34/100\n","50000/50000 [==============================] - 18s 356us/step - loss: 2.3090 - accuracy: 0.1008 - val_loss: 2.3073 - val_accuracy: 0.1000\n","Epoch 35/100\n","50000/50000 [==============================] - 18s 352us/step - loss: 2.3085 - accuracy: 0.1013 - val_loss: 2.3094 - val_accuracy: 0.1000\n","Epoch 36/100\n","50000/50000 [==============================] - 18s 351us/step - loss: 2.3092 - accuracy: 0.0999 - val_loss: 2.3082 - val_accuracy: 0.1000\n","Epoch 37/100\n","50000/50000 [==============================] - 18s 353us/step - loss: 2.3086 - accuracy: 0.0993 - val_loss: 2.3097 - val_accuracy: 0.1000\n","Epoch 38/100\n","50000/50000 [==============================] - 17s 349us/step - loss: 2.3087 - accuracy: 0.1003 - val_loss: 2.3050 - val_accuracy: 0.1000\n","Epoch 39/100\n","50000/50000 [==============================] - 18s 367us/step - loss: 2.3087 - accuracy: 0.0998 - val_loss: 2.3115 - val_accuracy: 0.1000\n","Epoch 40/100\n","50000/50000 [==============================] - 17s 348us/step - loss: 2.3087 - accuracy: 0.0992 - val_loss: 2.3061 - val_accuracy: 0.1000\n","Epoch 41/100\n","50000/50000 [==============================] - 18s 354us/step - loss: 2.3090 - accuracy: 0.0992 - val_loss: 2.3081 - val_accuracy: 0.1000\n","Epoch 42/100\n","50000/50000 [==============================] - 18s 355us/step - loss: 2.3088 - accuracy: 0.1005 - val_loss: 2.3056 - val_accuracy: 0.1000\n","Epoch 43/100\n","50000/50000 [==============================] - 18s 354us/step - loss: 2.3082 - accuracy: 0.1021 - val_loss: 2.3104 - val_accuracy: 0.1000\n","Epoch 44/100\n","50000/50000 [==============================] - 18s 353us/step - loss: 2.3084 - accuracy: 0.0997 - val_loss: 2.3073 - val_accuracy: 0.1000\n","Epoch 45/100\n","50000/50000 [==============================] - 18s 359us/step - loss: 2.3089 - accuracy: 0.1008 - val_loss: 2.3075 - val_accuracy: 0.1000\n","Epoch 46/100\n","50000/50000 [==============================] - 18s 355us/step - loss: 2.3088 - accuracy: 0.1003 - val_loss: 2.3126 - val_accuracy: 0.1000\n","Epoch 47/100\n","50000/50000 [==============================] - 18s 359us/step - loss: 2.3089 - accuracy: 0.1004 - val_loss: 2.3113 - val_accuracy: 0.1000\n","Epoch 48/100\n","50000/50000 [==============================] - 18s 357us/step - loss: 2.3095 - accuracy: 0.0995 - val_loss: 2.3055 - val_accuracy: 0.1000\n","Epoch 49/100\n","50000/50000 [==============================] - 18s 355us/step - loss: 2.3089 - accuracy: 0.0994 - val_loss: 2.3121 - val_accuracy: 0.1000\n","Epoch 50/100\n","50000/50000 [==============================] - 18s 358us/step - loss: 2.3085 - accuracy: 0.0978 - val_loss: 2.3095 - val_accuracy: 0.1000\n","Epoch 51/100\n","50000/50000 [==============================] - 18s 352us/step - loss: 2.3084 - accuracy: 0.1003 - val_loss: 2.3121 - val_accuracy: 0.1000\n","Epoch 52/100\n","50000/50000 [==============================] - 18s 355us/step - loss: 2.3090 - accuracy: 0.0995 - val_loss: 2.3082 - val_accuracy: 0.1000\n","Epoch 53/100\n","50000/50000 [==============================] - 18s 357us/step - loss: 2.3088 - accuracy: 0.1000 - val_loss: 2.3170 - val_accuracy: 0.1000\n","Epoch 54/100\n","50000/50000 [==============================] - 18s 356us/step - loss: 2.3091 - accuracy: 0.0979 - val_loss: 2.3087 - val_accuracy: 0.1000\n","Epoch 55/100\n","50000/50000 [==============================] - 18s 354us/step - loss: 2.3085 - accuracy: 0.1003 - val_loss: 2.3133 - val_accuracy: 0.1000\n","Epoch 56/100\n","50000/50000 [==============================] - 18s 363us/step - loss: 2.3086 - accuracy: 0.0999 - val_loss: 2.3079 - val_accuracy: 0.1000\n","Epoch 57/100\n","50000/50000 [==============================] - 18s 367us/step - loss: 2.3092 - accuracy: 0.1005 - val_loss: 2.3099 - val_accuracy: 0.1000\n","Epoch 58/100\n","50000/50000 [==============================] - 18s 361us/step - loss: 2.3087 - accuracy: 0.0988 - val_loss: 2.3055 - val_accuracy: 0.1000\n","Epoch 59/100\n","50000/50000 [==============================] - 18s 356us/step - loss: 2.3086 - accuracy: 0.1000 - val_loss: 2.3058 - val_accuracy: 0.1000\n","Epoch 60/100\n","50000/50000 [==============================] - 18s 352us/step - loss: 2.3081 - accuracy: 0.0992 - val_loss: 2.3068 - val_accuracy: 0.1000\n","Epoch 61/100\n","50000/50000 [==============================] - 17s 348us/step - loss: 2.3093 - accuracy: 0.0986 - val_loss: 2.3107 - val_accuracy: 0.1000\n","Epoch 62/100\n","50000/50000 [==============================] - 18s 358us/step - loss: 2.3086 - accuracy: 0.0976 - val_loss: 2.3056 - val_accuracy: 0.1000\n","Epoch 63/100\n","50000/50000 [==============================] - 18s 352us/step - loss: 2.3091 - accuracy: 0.1003 - val_loss: 2.3079 - val_accuracy: 0.1000\n","Epoch 64/100\n","50000/50000 [==============================] - 18s 352us/step - loss: 2.3086 - accuracy: 0.1013 - val_loss: 2.3089 - val_accuracy: 0.1000\n","Epoch 65/100\n","50000/50000 [==============================] - 18s 352us/step - loss: 2.3089 - accuracy: 0.1012 - val_loss: 2.3088 - val_accuracy: 0.1000\n","Epoch 66/100\n","50000/50000 [==============================] - 18s 354us/step - loss: 2.3086 - accuracy: 0.1010 - val_loss: 2.3106 - val_accuracy: 0.1000\n","Epoch 67/100\n","50000/50000 [==============================] - 18s 353us/step - loss: 2.3083 - accuracy: 0.0993 - val_loss: 2.3057 - val_accuracy: 0.1000\n","Epoch 68/100\n","50000/50000 [==============================] - 17s 350us/step - loss: 2.3091 - accuracy: 0.1017 - val_loss: 2.3075 - val_accuracy: 0.1000\n","Epoch 69/100\n","50000/50000 [==============================] - 18s 351us/step - loss: 2.3090 - accuracy: 0.1002 - val_loss: 2.3065 - val_accuracy: 0.1000\n","Epoch 70/100\n","50000/50000 [==============================] - 17s 350us/step - loss: 2.3081 - accuracy: 0.1006 - val_loss: 2.3062 - val_accuracy: 0.1000\n","Epoch 71/100\n","50000/50000 [==============================] - 18s 351us/step - loss: 2.3089 - accuracy: 0.0986 - val_loss: 2.3059 - val_accuracy: 0.1000\n","Epoch 72/100\n","50000/50000 [==============================] - 18s 351us/step - loss: 2.3084 - accuracy: 0.1006 - val_loss: 2.3066 - val_accuracy: 0.1000\n","Epoch 73/100\n","50000/50000 [==============================] - 18s 352us/step - loss: 2.3082 - accuracy: 0.1004 - val_loss: 2.3079 - val_accuracy: 0.1000\n","Epoch 74/100\n","50000/50000 [==============================] - 18s 365us/step - loss: 2.3088 - accuracy: 0.0996 - val_loss: 2.3064 - val_accuracy: 0.1000\n","Epoch 75/100\n","50000/50000 [==============================] - 18s 358us/step - loss: 2.3085 - accuracy: 0.1002 - val_loss: 2.3067 - val_accuracy: 0.1000\n","Epoch 76/100\n","50000/50000 [==============================] - 18s 352us/step - loss: 2.3085 - accuracy: 0.0995 - val_loss: 2.3046 - val_accuracy: 0.1000\n","Epoch 77/100\n","50000/50000 [==============================] - 17s 349us/step - loss: 2.3085 - accuracy: 0.0976 - val_loss: 2.3105 - val_accuracy: 0.1000\n","Epoch 78/100\n","50000/50000 [==============================] - 18s 351us/step - loss: 2.3087 - accuracy: 0.1015 - val_loss: 2.3134 - val_accuracy: 0.1000\n","Epoch 79/100\n","50000/50000 [==============================] - 17s 350us/step - loss: 2.3084 - accuracy: 0.0990 - val_loss: 2.3122 - val_accuracy: 0.1000\n","Epoch 80/100\n","50000/50000 [==============================] - 18s 356us/step - loss: 2.3082 - accuracy: 0.0992 - val_loss: 2.3054 - val_accuracy: 0.1000\n","Epoch 81/100\n","50000/50000 [==============================] - 17s 347us/step - loss: 2.3087 - accuracy: 0.0992 - val_loss: 2.3064 - val_accuracy: 0.1000\n","Epoch 82/100\n","50000/50000 [==============================] - 17s 349us/step - loss: 2.3084 - accuracy: 0.1021 - val_loss: 2.3085 - val_accuracy: 0.1000\n","Epoch 83/100\n","50000/50000 [==============================] - 18s 351us/step - loss: 2.3084 - accuracy: 0.0996 - val_loss: 2.3071 - val_accuracy: 0.1000\n","Epoch 84/100\n","50000/50000 [==============================] - 17s 349us/step - loss: 2.3085 - accuracy: 0.0978 - val_loss: 2.3058 - val_accuracy: 0.1000\n","Epoch 85/100\n","50000/50000 [==============================] - 18s 350us/step - loss: 2.3081 - accuracy: 0.0977 - val_loss: 2.3100 - val_accuracy: 0.1000\n","Epoch 86/100\n","50000/50000 [==============================] - 18s 354us/step - loss: 2.3086 - accuracy: 0.1017 - val_loss: 2.3093 - val_accuracy: 0.1000\n","Epoch 87/100\n","50000/50000 [==============================] - 18s 358us/step - loss: 2.3084 - accuracy: 0.0999 - val_loss: 2.3082 - val_accuracy: 0.1000\n","Epoch 88/100\n","50000/50000 [==============================] - 18s 354us/step - loss: 2.3084 - accuracy: 0.1008 - val_loss: 2.3106 - val_accuracy: 0.1000\n","Epoch 89/100\n","50000/50000 [==============================] - 18s 357us/step - loss: 2.3087 - accuracy: 0.0985 - val_loss: 2.3092 - val_accuracy: 0.1000\n","Epoch 90/100\n","50000/50000 [==============================] - 18s 352us/step - loss: 2.3083 - accuracy: 0.1012 - val_loss: 2.3068 - val_accuracy: 0.1000\n","Epoch 91/100\n","50000/50000 [==============================] - 18s 356us/step - loss: 2.3086 - accuracy: 0.0990 - val_loss: 2.3080 - val_accuracy: 0.1000\n","Epoch 92/100\n","50000/50000 [==============================] - 19s 371us/step - loss: 2.3086 - accuracy: 0.0984 - val_loss: 2.3060 - val_accuracy: 0.1000\n","Epoch 93/100\n","50000/50000 [==============================] - 18s 356us/step - loss: 2.3083 - accuracy: 0.0989 - val_loss: 2.3050 - val_accuracy: 0.1000\n","Epoch 94/100\n","50000/50000 [==============================] - 18s 355us/step - loss: 2.3077 - accuracy: 0.1013 - val_loss: 2.3097 - val_accuracy: 0.1000\n","Epoch 95/100\n","50000/50000 [==============================] - 18s 355us/step - loss: 2.3083 - accuracy: 0.0984 - val_loss: 2.3062 - val_accuracy: 0.1000\n","Epoch 96/100\n","50000/50000 [==============================] - 18s 353us/step - loss: 2.3080 - accuracy: 0.0994 - val_loss: 2.3076 - val_accuracy: 0.1000\n","Epoch 97/100\n","50000/50000 [==============================] - 18s 359us/step - loss: 2.3084 - accuracy: 0.1003 - val_loss: 2.3101 - val_accuracy: 0.1000\n","Epoch 98/100\n","50000/50000 [==============================] - 18s 354us/step - loss: 2.3092 - accuracy: 0.1003 - val_loss: 2.3063 - val_accuracy: 0.1000\n","Epoch 99/100\n","50000/50000 [==============================] - 18s 351us/step - loss: 2.3083 - accuracy: 0.1002 - val_loss: 2.3077 - val_accuracy: 0.1000\n","Epoch 100/100\n","50000/50000 [==============================] - 18s 354us/step - loss: 2.3084 - accuracy: 0.0998 - val_loss: 2.3107 - val_accuracy: 0.1000\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"_uuid":"60f2c47a3f16dfddf76e260a75203d8df905935b","id":"gO_t-G5Hq3-A","colab_type":"text"},"source":["# 6 Layer Model\n","We will now create a 6 layer model to compare with the 4 layer model created above. "]},{"cell_type":"code","metadata":{"trusted":true,"_uuid":"e26a1ff8cf174c40e5a734a34f1c2887556f47f0","id":"BnEK1YTbq3-B","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1593296929484,"user_tz":300,"elapsed":3554154,"user":{"displayName":"hendrik Martina","photoUrl":"","userId":"05716117210214543831"}},"outputId":"d7929b10-ae2e-455d-bc4c-9fe9400b8f8a"},"source":["def six_layer():\n","    model = Sequential()\n","    \n","    model.add(Conv2D(32, (3, 3), padding='same', activation='relu', input_shape=x_train.shape[1:]))\n","    model.add(Dropout(0.2))\n","    \n","    model.add(Conv2D(32,(3,3),padding='same', activation='relu'))\n","    model.add(MaxPooling2D(pool_size=(2,2)))\n","    \n","    model.add(Conv2D(64,(3,3),padding='same',activation='relu'))\n","    model.add(Dropout(0.2))\n","    \n","    model.add(Conv2D(64,(3,3),padding='same',activation='relu'))\n","    model.add(MaxPooling2D(pool_size=(2,2)))\n","    \n","    model.add(Conv2D(128,(3,3),padding='same',activation='relu'))\n","    model.add(Dropout(0.2))\n","    \n","    model.add(Conv2D(128,(3,3),padding='same',activation='relu'))\n","    model.add(MaxPooling2D(pool_size=(2,2)))\n","    \n","    model.add(Flatten())\n","    model.add(Dropout(0.2))\n","    model.add(Dense(1024,activation='relu',kernel_constraint=maxnorm(3)))\n","    model.add(Dropout(0.2))\n","    model.add(Dense(num_classes, activation='softmax'))\n","    \n","    sgd = SGD(lr = 0.1, decay=1e-6, momentum=0.9, nesterov=True)\n","    \n","    # Train model\n","    model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n","    return model\n","cnn_n6 = six_layer()\n","cnn_n6.summary()\n"," \n","# Fit model\n"," \n","cnn6 = cnn_n.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_data=(x_test,y_test),shuffle=True)"],"execution_count":11,"outputs":[{"output_type":"stream","text":["Model: \"sequential_2\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d_5 (Conv2D)            (None, 32, 32, 32)        896       \n","_________________________________________________________________\n","dropout_4 (Dropout)          (None, 32, 32, 32)        0         \n","_________________________________________________________________\n","conv2d_6 (Conv2D)            (None, 32, 32, 32)        9248      \n","_________________________________________________________________\n","max_pooling2d_3 (MaxPooling2 (None, 16, 16, 32)        0         \n","_________________________________________________________________\n","conv2d_7 (Conv2D)            (None, 16, 16, 64)        18496     \n","_________________________________________________________________\n","dropout_5 (Dropout)          (None, 16, 16, 64)        0         \n","_________________________________________________________________\n","conv2d_8 (Conv2D)            (None, 16, 16, 64)        36928     \n","_________________________________________________________________\n","max_pooling2d_4 (MaxPooling2 (None, 8, 8, 64)          0         \n","_________________________________________________________________\n","conv2d_9 (Conv2D)            (None, 8, 8, 128)         73856     \n","_________________________________________________________________\n","dropout_6 (Dropout)          (None, 8, 8, 128)         0         \n","_________________________________________________________________\n","conv2d_10 (Conv2D)           (None, 8, 8, 128)         147584    \n","_________________________________________________________________\n","max_pooling2d_5 (MaxPooling2 (None, 4, 4, 128)         0         \n","_________________________________________________________________\n","flatten_2 (Flatten)          (None, 2048)              0         \n","_________________________________________________________________\n","dropout_7 (Dropout)          (None, 2048)              0         \n","_________________________________________________________________\n","dense_3 (Dense)              (None, 1024)              2098176   \n","_________________________________________________________________\n","dropout_8 (Dropout)          (None, 1024)              0         \n","_________________________________________________________________\n","dense_4 (Dense)              (None, 10)                10250     \n","=================================================================\n","Total params: 2,395,434\n","Trainable params: 2,395,434\n","Non-trainable params: 0\n","_________________________________________________________________\n","Train on 50000 samples, validate on 10000 samples\n","Epoch 1/100\n","50000/50000 [==============================] - 18s 355us/step - loss: 2.3081 - accuracy: 0.0988 - val_loss: 2.3045 - val_accuracy: 0.1000\n","Epoch 2/100\n","50000/50000 [==============================] - 18s 354us/step - loss: 2.3083 - accuracy: 0.1005 - val_loss: 2.3092 - val_accuracy: 0.1000\n","Epoch 3/100\n","50000/50000 [==============================] - 18s 354us/step - loss: 2.3082 - accuracy: 0.1002 - val_loss: 2.3099 - val_accuracy: 0.1000\n","Epoch 4/100\n","50000/50000 [==============================] - 17s 348us/step - loss: 2.3080 - accuracy: 0.0978 - val_loss: 2.3136 - val_accuracy: 0.1000\n","Epoch 5/100\n","50000/50000 [==============================] - 17s 350us/step - loss: 2.3086 - accuracy: 0.1008 - val_loss: 2.3106 - val_accuracy: 0.1000\n","Epoch 6/100\n","50000/50000 [==============================] - 18s 351us/step - loss: 2.3087 - accuracy: 0.0968 - val_loss: 2.3073 - val_accuracy: 0.1000\n","Epoch 7/100\n","50000/50000 [==============================] - 18s 354us/step - loss: 2.3084 - accuracy: 0.0999 - val_loss: 2.3091 - val_accuracy: 0.1000\n","Epoch 8/100\n","50000/50000 [==============================] - 18s 351us/step - loss: 2.3087 - accuracy: 0.0979 - val_loss: 2.3050 - val_accuracy: 0.1000\n","Epoch 9/100\n","50000/50000 [==============================] - 18s 367us/step - loss: 2.3088 - accuracy: 0.1001 - val_loss: 2.3077 - val_accuracy: 0.1000\n","Epoch 10/100\n","50000/50000 [==============================] - 18s 357us/step - loss: 2.3086 - accuracy: 0.0994 - val_loss: 2.3104 - val_accuracy: 0.1000\n","Epoch 11/100\n","50000/50000 [==============================] - 18s 354us/step - loss: 2.3085 - accuracy: 0.0993 - val_loss: 2.3158 - val_accuracy: 0.1000\n","Epoch 12/100\n","50000/50000 [==============================] - 18s 350us/step - loss: 2.3084 - accuracy: 0.1005 - val_loss: 2.3094 - val_accuracy: 0.1000\n","Epoch 13/100\n","50000/50000 [==============================] - 18s 351us/step - loss: 2.3086 - accuracy: 0.1007 - val_loss: 2.3092 - val_accuracy: 0.1000\n","Epoch 14/100\n","50000/50000 [==============================] - 18s 358us/step - loss: 2.3078 - accuracy: 0.1008 - val_loss: 2.3050 - val_accuracy: 0.1000\n","Epoch 15/100\n","50000/50000 [==============================] - 17s 349us/step - loss: 2.3083 - accuracy: 0.0998 - val_loss: 2.3079 - val_accuracy: 0.1000\n","Epoch 16/100\n","50000/50000 [==============================] - 17s 349us/step - loss: 2.3082 - accuracy: 0.1008 - val_loss: 2.3105 - val_accuracy: 0.1000\n","Epoch 17/100\n","50000/50000 [==============================] - 17s 349us/step - loss: 2.3089 - accuracy: 0.0986 - val_loss: 2.3084 - val_accuracy: 0.1000\n","Epoch 18/100\n","50000/50000 [==============================] - 17s 349us/step - loss: 2.3083 - accuracy: 0.0998 - val_loss: 2.3093 - val_accuracy: 0.1000\n","Epoch 19/100\n","50000/50000 [==============================] - 17s 347us/step - loss: 2.3088 - accuracy: 0.0986 - val_loss: 2.3090 - val_accuracy: 0.1000\n","Epoch 20/100\n","50000/50000 [==============================] - 17s 350us/step - loss: 2.3082 - accuracy: 0.0976 - val_loss: 2.3129 - val_accuracy: 0.1000\n","Epoch 21/100\n","50000/50000 [==============================] - 17s 349us/step - loss: 2.3084 - accuracy: 0.0994 - val_loss: 2.3057 - val_accuracy: 0.1000\n","Epoch 22/100\n","50000/50000 [==============================] - 17s 348us/step - loss: 2.3084 - accuracy: 0.0980 - val_loss: 2.3071 - val_accuracy: 0.1000\n","Epoch 23/100\n","50000/50000 [==============================] - 17s 350us/step - loss: 2.3086 - accuracy: 0.0971 - val_loss: 2.3073 - val_accuracy: 0.1000\n","Epoch 24/100\n","50000/50000 [==============================] - 17s 348us/step - loss: 2.3083 - accuracy: 0.1002 - val_loss: 2.3064 - val_accuracy: 0.1000\n","Epoch 25/100\n","50000/50000 [==============================] - 17s 349us/step - loss: 2.3083 - accuracy: 0.0992 - val_loss: 2.3041 - val_accuracy: 0.1000\n","Epoch 26/100\n","50000/50000 [==============================] - 17s 348us/step - loss: 2.3085 - accuracy: 0.0997 - val_loss: 2.3062 - val_accuracy: 0.1000\n","Epoch 27/100\n","50000/50000 [==============================] - 18s 362us/step - loss: 2.3081 - accuracy: 0.0984 - val_loss: 2.3106 - val_accuracy: 0.1000\n","Epoch 28/100\n","50000/50000 [==============================] - 17s 350us/step - loss: 2.3082 - accuracy: 0.1010 - val_loss: 2.3074 - val_accuracy: 0.1000\n","Epoch 29/100\n","50000/50000 [==============================] - 17s 348us/step - loss: 2.3083 - accuracy: 0.0987 - val_loss: 2.3117 - val_accuracy: 0.1000\n","Epoch 30/100\n","50000/50000 [==============================] - 17s 348us/step - loss: 2.3082 - accuracy: 0.1006 - val_loss: 2.3047 - val_accuracy: 0.1000\n","Epoch 31/100\n","50000/50000 [==============================] - 18s 355us/step - loss: 2.3077 - accuracy: 0.1011 - val_loss: 2.3053 - val_accuracy: 0.1000\n","Epoch 32/100\n","50000/50000 [==============================] - 18s 358us/step - loss: 2.3080 - accuracy: 0.0994 - val_loss: 2.3114 - val_accuracy: 0.1000\n","Epoch 33/100\n","50000/50000 [==============================] - 18s 354us/step - loss: 2.3080 - accuracy: 0.1020 - val_loss: 2.3104 - val_accuracy: 0.1000\n","Epoch 34/100\n","50000/50000 [==============================] - 18s 354us/step - loss: 2.3081 - accuracy: 0.1008 - val_loss: 2.3086 - val_accuracy: 0.1000\n","Epoch 35/100\n","50000/50000 [==============================] - 18s 354us/step - loss: 2.3083 - accuracy: 0.0968 - val_loss: 2.3052 - val_accuracy: 0.1000\n","Epoch 36/100\n","50000/50000 [==============================] - 18s 353us/step - loss: 2.3086 - accuracy: 0.0994 - val_loss: 2.3049 - val_accuracy: 0.1000\n","Epoch 37/100\n","50000/50000 [==============================] - 18s 352us/step - loss: 2.3078 - accuracy: 0.1008 - val_loss: 2.3086 - val_accuracy: 0.1000\n","Epoch 38/100\n","50000/50000 [==============================] - 18s 355us/step - loss: 2.3082 - accuracy: 0.0969 - val_loss: 2.3051 - val_accuracy: 0.1000\n","Epoch 39/100\n","50000/50000 [==============================] - 18s 354us/step - loss: 2.3085 - accuracy: 0.1000 - val_loss: 2.3126 - val_accuracy: 0.1000\n","Epoch 40/100\n","50000/50000 [==============================] - 18s 355us/step - loss: 2.3082 - accuracy: 0.0992 - val_loss: 2.3100 - val_accuracy: 0.1000\n","Epoch 41/100\n","50000/50000 [==============================] - 18s 354us/step - loss: 2.3083 - accuracy: 0.0998 - val_loss: 2.3048 - val_accuracy: 0.1000\n","Epoch 42/100\n","50000/50000 [==============================] - 18s 355us/step - loss: 2.3077 - accuracy: 0.1009 - val_loss: 2.3081 - val_accuracy: 0.1000\n","Epoch 43/100\n","50000/50000 [==============================] - 18s 353us/step - loss: 2.3081 - accuracy: 0.0995 - val_loss: 2.3057 - val_accuracy: 0.1000\n","Epoch 44/100\n","50000/50000 [==============================] - 18s 362us/step - loss: 2.3082 - accuracy: 0.0992 - val_loss: 2.3063 - val_accuracy: 0.1000\n","Epoch 45/100\n","50000/50000 [==============================] - 18s 370us/step - loss: 2.3077 - accuracy: 0.1004 - val_loss: 2.3103 - val_accuracy: 0.1000\n","Epoch 46/100\n","50000/50000 [==============================] - 18s 359us/step - loss: 2.3083 - accuracy: 0.0987 - val_loss: 2.3091 - val_accuracy: 0.1000\n","Epoch 47/100\n","50000/50000 [==============================] - 18s 353us/step - loss: 2.3081 - accuracy: 0.0992 - val_loss: 2.3043 - val_accuracy: 0.1000\n","Epoch 48/100\n","50000/50000 [==============================] - 18s 352us/step - loss: 2.3078 - accuracy: 0.1004 - val_loss: 2.3053 - val_accuracy: 0.1000\n","Epoch 49/100\n","50000/50000 [==============================] - 18s 358us/step - loss: 2.3082 - accuracy: 0.0991 - val_loss: 2.3095 - val_accuracy: 0.1000\n","Epoch 50/100\n","50000/50000 [==============================] - 18s 351us/step - loss: 2.3078 - accuracy: 0.1012 - val_loss: 2.3049 - val_accuracy: 0.1000\n","Epoch 51/100\n","50000/50000 [==============================] - 18s 352us/step - loss: 2.3078 - accuracy: 0.1013 - val_loss: 2.3109 - val_accuracy: 0.1000\n","Epoch 52/100\n","50000/50000 [==============================] - 18s 353us/step - loss: 2.3079 - accuracy: 0.1010 - val_loss: 2.3113 - val_accuracy: 0.1000\n","Epoch 53/100\n","50000/50000 [==============================] - 18s 351us/step - loss: 2.3077 - accuracy: 0.1004 - val_loss: 2.3083 - val_accuracy: 0.1000\n","Epoch 54/100\n","50000/50000 [==============================] - 18s 351us/step - loss: 2.3076 - accuracy: 0.1021 - val_loss: 2.3144 - val_accuracy: 0.1000\n","Epoch 55/100\n","50000/50000 [==============================] - 18s 352us/step - loss: 2.3078 - accuracy: 0.1003 - val_loss: 2.3108 - val_accuracy: 0.1000\n","Epoch 56/100\n","50000/50000 [==============================] - 17s 349us/step - loss: 2.3083 - accuracy: 0.0986 - val_loss: 2.3091 - val_accuracy: 0.1000\n","Epoch 57/100\n","50000/50000 [==============================] - 18s 350us/step - loss: 2.3080 - accuracy: 0.0977 - val_loss: 2.3059 - val_accuracy: 0.1000\n","Epoch 58/100\n","50000/50000 [==============================] - 18s 350us/step - loss: 2.3080 - accuracy: 0.0979 - val_loss: 2.3096 - val_accuracy: 0.1000\n","Epoch 59/100\n","50000/50000 [==============================] - 18s 352us/step - loss: 2.3078 - accuracy: 0.0997 - val_loss: 2.3111 - val_accuracy: 0.1000\n","Epoch 60/100\n","50000/50000 [==============================] - 18s 352us/step - loss: 2.3076 - accuracy: 0.1003 - val_loss: 2.3072 - val_accuracy: 0.1000\n","Epoch 61/100\n","50000/50000 [==============================] - 18s 353us/step - loss: 2.3079 - accuracy: 0.1003 - val_loss: 2.3103 - val_accuracy: 0.1000\n","Epoch 62/100\n","50000/50000 [==============================] - 18s 363us/step - loss: 2.3079 - accuracy: 0.1002 - val_loss: 2.3063 - val_accuracy: 0.1000\n","Epoch 63/100\n","50000/50000 [==============================] - 18s 351us/step - loss: 2.3076 - accuracy: 0.0997 - val_loss: 2.3086 - val_accuracy: 0.1000\n","Epoch 64/100\n","50000/50000 [==============================] - 18s 352us/step - loss: 2.3079 - accuracy: 0.0981 - val_loss: 2.3094 - val_accuracy: 0.1000\n","Epoch 65/100\n","50000/50000 [==============================] - 18s 351us/step - loss: 2.3077 - accuracy: 0.0996 - val_loss: 2.3047 - val_accuracy: 0.1000\n","Epoch 66/100\n","50000/50000 [==============================] - 18s 357us/step - loss: 2.3079 - accuracy: 0.1012 - val_loss: 2.3067 - val_accuracy: 0.1000\n","Epoch 67/100\n","50000/50000 [==============================] - 18s 353us/step - loss: 2.3081 - accuracy: 0.0995 - val_loss: 2.3094 - val_accuracy: 0.1000\n","Epoch 68/100\n","50000/50000 [==============================] - 18s 353us/step - loss: 2.3076 - accuracy: 0.1004 - val_loss: 2.3113 - val_accuracy: 0.1000\n","Epoch 69/100\n","50000/50000 [==============================] - 18s 352us/step - loss: 2.3075 - accuracy: 0.1019 - val_loss: 2.3093 - val_accuracy: 0.1000\n","Epoch 70/100\n","50000/50000 [==============================] - 18s 352us/step - loss: 2.3080 - accuracy: 0.0994 - val_loss: 2.3060 - val_accuracy: 0.1000\n","Epoch 71/100\n","50000/50000 [==============================] - 18s 352us/step - loss: 2.3080 - accuracy: 0.1006 - val_loss: 2.3084 - val_accuracy: 0.1000\n","Epoch 72/100\n","50000/50000 [==============================] - 18s 353us/step - loss: 2.3075 - accuracy: 0.0998 - val_loss: 2.3038 - val_accuracy: 0.1000\n","Epoch 73/100\n","50000/50000 [==============================] - 18s 351us/step - loss: 2.3081 - accuracy: 0.0998 - val_loss: 2.3089 - val_accuracy: 0.1000\n","Epoch 74/100\n","50000/50000 [==============================] - 18s 352us/step - loss: 2.3078 - accuracy: 0.1013 - val_loss: 2.3067 - val_accuracy: 0.1000\n","Epoch 75/100\n","50000/50000 [==============================] - 18s 353us/step - loss: 2.3081 - accuracy: 0.0991 - val_loss: 2.3093 - val_accuracy: 0.1000\n","Epoch 76/100\n","50000/50000 [==============================] - 18s 356us/step - loss: 2.3082 - accuracy: 0.1001 - val_loss: 2.3041 - val_accuracy: 0.1000\n","Epoch 77/100\n","50000/50000 [==============================] - 18s 353us/step - loss: 2.3075 - accuracy: 0.1018 - val_loss: 2.3089 - val_accuracy: 0.1000\n","Epoch 78/100\n","50000/50000 [==============================] - 18s 354us/step - loss: 2.3084 - accuracy: 0.0999 - val_loss: 2.3080 - val_accuracy: 0.1000\n","Epoch 79/100\n","50000/50000 [==============================] - 18s 359us/step - loss: 2.3078 - accuracy: 0.0983 - val_loss: 2.3074 - val_accuracy: 0.1000\n","Epoch 80/100\n","50000/50000 [==============================] - 18s 370us/step - loss: 2.3075 - accuracy: 0.0982 - val_loss: 2.3059 - val_accuracy: 0.1000\n","Epoch 81/100\n","50000/50000 [==============================] - 18s 353us/step - loss: 2.3075 - accuracy: 0.1014 - val_loss: 2.3071 - val_accuracy: 0.1000\n","Epoch 82/100\n","50000/50000 [==============================] - 18s 355us/step - loss: 2.3079 - accuracy: 0.1015 - val_loss: 2.3043 - val_accuracy: 0.1000\n","Epoch 83/100\n","50000/50000 [==============================] - 18s 360us/step - loss: 2.3079 - accuracy: 0.0996 - val_loss: 2.3242 - val_accuracy: 0.1000\n","Epoch 84/100\n","50000/50000 [==============================] - 18s 350us/step - loss: 2.3079 - accuracy: 0.0999 - val_loss: 2.3092 - val_accuracy: 0.1000\n","Epoch 85/100\n","50000/50000 [==============================] - 18s 353us/step - loss: 2.3078 - accuracy: 0.1020 - val_loss: 2.3082 - val_accuracy: 0.1000\n","Epoch 86/100\n","50000/50000 [==============================] - 18s 351us/step - loss: 2.3075 - accuracy: 0.0992 - val_loss: 2.3081 - val_accuracy: 0.1000\n","Epoch 87/100\n","50000/50000 [==============================] - 18s 353us/step - loss: 2.3077 - accuracy: 0.0988 - val_loss: 2.3078 - val_accuracy: 0.1000\n","Epoch 88/100\n","50000/50000 [==============================] - 18s 352us/step - loss: 2.3077 - accuracy: 0.1000 - val_loss: 2.3089 - val_accuracy: 0.1000\n","Epoch 89/100\n","50000/50000 [==============================] - 18s 354us/step - loss: 2.3074 - accuracy: 0.1017 - val_loss: 2.3094 - val_accuracy: 0.1000\n","Epoch 90/100\n","50000/50000 [==============================] - 18s 353us/step - loss: 2.3076 - accuracy: 0.1000 - val_loss: 2.3099 - val_accuracy: 0.1000\n","Epoch 91/100\n","50000/50000 [==============================] - 18s 351us/step - loss: 2.3080 - accuracy: 0.1008 - val_loss: 2.3054 - val_accuracy: 0.1000\n","Epoch 92/100\n","50000/50000 [==============================] - 17s 349us/step - loss: 2.3078 - accuracy: 0.0989 - val_loss: 2.3108 - val_accuracy: 0.1000\n","Epoch 93/100\n","50000/50000 [==============================] - 18s 350us/step - loss: 2.3081 - accuracy: 0.0995 - val_loss: 2.3124 - val_accuracy: 0.1000\n","Epoch 94/100\n","50000/50000 [==============================] - 18s 350us/step - loss: 2.3076 - accuracy: 0.0996 - val_loss: 2.3087 - val_accuracy: 0.1000\n","Epoch 95/100\n","50000/50000 [==============================] - 18s 351us/step - loss: 2.3079 - accuracy: 0.0996 - val_loss: 2.3108 - val_accuracy: 0.1000\n","Epoch 96/100\n","50000/50000 [==============================] - 18s 353us/step - loss: 2.3079 - accuracy: 0.0994 - val_loss: 2.3076 - val_accuracy: 0.1000\n","Epoch 97/100\n","50000/50000 [==============================] - 19s 372us/step - loss: 2.3077 - accuracy: 0.1001 - val_loss: 2.3055 - val_accuracy: 0.1000\n","Epoch 98/100\n","50000/50000 [==============================] - 18s 356us/step - loss: 2.3080 - accuracy: 0.0975 - val_loss: 2.3048 - val_accuracy: 0.1000\n","Epoch 99/100\n","50000/50000 [==============================] - 18s 354us/step - loss: 2.3081 - accuracy: 0.1000 - val_loss: 2.3079 - val_accuracy: 0.1000\n","Epoch 100/100\n","50000/50000 [==============================] - 18s 352us/step - loss: 2.3081 - accuracy: 0.0981 - val_loss: 2.3069 - val_accuracy: 0.1000\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"_uuid":"e9532be4d764a838e540d01a28932a56865a5ee6","id":"3FOq-WAFq3-J","colab_type":"text"},"source":["# Plotting our accuracy and loss\n","\n","# 4 Layer CNN"]},{"cell_type":"code","metadata":{"trusted":true,"_uuid":"3c33e393447b700f02b5616f67ff8027c9fe011f","id":"_oJjPWVVq3-K","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":236},"executionInfo":{"status":"error","timestamp":1593296929816,"user_tz":300,"elapsed":3554479,"user":{"displayName":"hendrik Martina","photoUrl":"","userId":"05716117210214543831"}},"outputId":"aac7ea2a-45a4-4452-ab48-616b1bde7b0d"},"source":["plt.figure(0)\n","plt.plot(cnn.history['acc'],'r')\n","plt.plot(cnn.history['val_acc'],'g')\n","plt.plot()"],"execution_count":12,"outputs":[{"output_type":"error","ename":"KeyError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m<ipython-input-12-57e762e0f480>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'g'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: 'acc'"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 0 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"trusted":true,"_uuid":"56b4c2ce7faee1056eca5fbac200cc0a36b0b2da","id":"hRM9I1QIq3-O","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1593296929485,"user_tz":300,"elapsed":3554143,"user":{"displayName":"hendrik Martina","photoUrl":"","userId":"05716117210214543831"}}},"source":["scores = cnn_n.evaluate(x_test, y_test, verbose=0)\n","print(\"Accuracy: %.2f%%\" % (scores[1]*100))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"_uuid":"e255d6958f56e0890dbe92c32407769961673be4","id":"Or9_zrhsq3-T","colab_type":"text"},"source":["# 6 Layer CNN"]},{"cell_type":"code","metadata":{"trusted":true,"_uuid":"8ad0824db1e826ef98f20052efe88250690b14f0","id":"AfmlFWNoq3-V","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1593296929487,"user_tz":300,"elapsed":3554143,"user":{"displayName":"hendrik Martina","photoUrl":"","userId":"05716117210214543831"}}},"source":["plt.figure(1)\n","plt.plot(cnn6.history['acc'],'r')\n","plt.plot(cnn6.history['val_acc'],'g')\n","plt.plot()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"trusted":true,"_uuid":"d7371dbf328642a2299b0916498a3b1bef23e854","id":"ouMLtV8wq3-Z","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1593296929487,"user_tz":300,"elapsed":3554139,"user":{"displayName":"hendrik Martina","photoUrl":"","userId":"05716117210214543831"}}},"source":["scores = cnn_n6.evaluate(x_test, y_test, verbose=0)\n","print(\"Accuracy: %.2f%%\" % (scores[1]*100))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"_uuid":"198dfc8675e01fa291e07debb3e8290edfdc4177","id":"QPYL3w6nq3-d","colab_type":"text"},"source":["# Confusion Matrix for 4 layer"]},{"cell_type":"code","metadata":{"trusted":true,"_uuid":"ea084dfeb822ed1834052c1cba4a656401971bce","id":"-mst7aNsq3-d","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1593296929488,"user_tz":300,"elapsed":3554135,"user":{"displayName":"hendrik Martina","photoUrl":"","userId":"05716117210214543831"}}},"source":["from sklearn.metrics import classification_report, confusion_matrix\n","Y_pred = cnn_n.predict(x_test, verbose=2)\n","y_pred = np.argmax(Y_pred, axis=1)\n"," \n","for ix in range(10):\n","    print(ix, confusion_matrix(np.argmax(y_test,axis=1),y_pred)[ix].sum())\n","cm = confusion_matrix(np.argmax(y_test,axis=1),y_pred)\n","print(cm)\n"," \n","# Visualizing of confusion matrix\n","import seaborn as sn\n","import pandas  as pd\n","\n","df_cm = pd.DataFrame(cm, range(10),range(10))\n","plt.figure(figsize = (10,7))\n","sn.set(font_scale=1.4)#for label size\n","sn.heatmap(df_cm, annot=True,annot_kws={\"size\": 12})# font size\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"_uuid":"0c5ae1b870a740c07f42bd2045a8cc781bbfb6d2","id":"kvjFaV-jq3-j","colab_type":"text"},"source":["# Confustion Matrix for 6 layer "]},{"cell_type":"code","metadata":{"trusted":true,"_uuid":"67a6b7adfe6b0b0c122f5db8e9da701ee09f4477","id":"DXFIjOQlq3-j","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1593296929490,"user_tz":300,"elapsed":3554132,"user":{"displayName":"hendrik Martina","photoUrl":"","userId":"05716117210214543831"}}},"source":["Y_pred = cnn_n6.predict(x_test, verbose=2)\n","y_pred = np.argmax(Y_pred, axis=1)\n"," \n","for ix in range(10):\n","    print(ix, confusion_matrix(np.argmax(y_test,axis=1),y_pred)[ix].sum())\n","cm = confusion_matrix(np.argmax(y_test,axis=1),y_pred)\n","print(cm)\n","\n","df_cm = pd.DataFrame(cm, range(10),range(10))\n","plt.figure(figsize = (10,7))\n","sn.set(font_scale=1.4)#for label size\n","sn.heatmap(df_cm, annot=True,annot_kws={\"size\": 12})# font size\n","plt.show()"],"execution_count":null,"outputs":[]}]}